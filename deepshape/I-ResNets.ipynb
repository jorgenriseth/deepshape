{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import relu, tanh\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (SpectralDenseLayer.py, line 50)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/jorgen/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3441\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/tmp/ipykernel_87511/2105044522.py\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from deepshape.curves import *\n",
      "  File \u001b[1;32m\"/home/jorgen/deepshape/deepshape/curves/__init__.py\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from .networks import *\n",
      "  File \u001b[1;32m\"/home/jorgen/deepshape/deepshape/curves/networks.py\"\u001b[0m, line \u001b[1;32m8\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from .layers import DeepShapeLayer\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/jorgen/deepshape/deepshape/curves/layers/__init__.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from .SpectralDenseLayer import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/jorgen/deepshape/deepshape/curves/layers/SpectralDenseLayer.py\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    with\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from deepshape.curves import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test curves\n",
    "g = LogStepDiff()\n",
    "\n",
    "c1 = Infinity()\n",
    "c2 = c1.compose(g)\n",
    "\n",
    "# Take Qmaps\n",
    "q, r = Qmap(c2), Qmap(c1)\n",
    "\n",
    "plt.figure(figsize=(8.3, 5.6))\n",
    "plot_curve(c1, dotpoints=21, ax=plt.gca())\n",
    "\n",
    "plt.figure(figsize=(8.3, 5.6))\n",
    "plot_curve(c2, dotpoints=21, ax=plt.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### \n",
    "# TEST: Spectral normalization algorithm\n",
    "#########\n",
    "test_iters = 100\n",
    "input_size = 100\n",
    "hidden_size = 110\n",
    "c = 0.9\n",
    "power_iters = 10\n",
    "\n",
    "def power_iteration(W: torch.Tensor, iters: int):\n",
    "    v = torch.rand(W.size(1))\n",
    "    vnorm = v.norm()\n",
    "\n",
    "    for i in range(iters):\n",
    "        v = torch.mv( torch.mm(W.transpose(1, 0), W), v / vnorm )\n",
    "        vnorm = v.norm()\n",
    "        \n",
    "    return (W @ v).norm() / vnorm\n",
    "\n",
    "def spectral_normalization(W : torch.Tensor, c : float, iters: int):\n",
    "    spec_norm = power_iteration(W, iters)\n",
    "    W /= max(1., spec_norm / c)\n",
    "    return W\n",
    "\n",
    "def nuclear_normalization(W : torch.Tensor, c : float, iters: int):\n",
    "    nuc_norm = torch.linalg.norm(W, 2)\n",
    "    W /= max(1., nuc_norm / c)\n",
    "    return W\n",
    "\n",
    "for i in range(test_iters):\n",
    "    v = torch.rand(input_size)\n",
    "    W0 = 100 * torch.randn(hidden_size, input_size)\n",
    "    W1 = nuclear_normalization(W0, c=0.95, iters=power_iters)\n",
    "    assert torch.linalg.norm(W1, 2) < 1.\n",
    "\n",
    "class SpectralDenseLayer(nn.Module):\n",
    "    def __init__(self, input_dim: int, out_dim: int = 1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         return x + self.layer2(torch.tanh(self.layer1(x)))\n",
    "        return min_max_norm(x + self.layer2(torch.tanh(self.layer1(x))))\n",
    "    \n",
    "    def project(self, c : float, iters: int = 5):\n",
    "        self.layer1.weight = nuclear_normalization(self.layer1.weight, c, iters)\n",
    "        self.layer2.weight = nuclear_normalization(self.layer2.weight, c, iters)\n",
    "        \n",
    "    def reparametrized(self, r, X):\n",
    "        Z = min_max_norm(network(x))\n",
    "        Y = central_diff_derivative(Z)\n",
    "        return torch.sqrt(Y) * r(Z)\n",
    "    \n",
    "    \n",
    "def min_max_norm(Z):\n",
    "    return (Z - Z[0]) / (Z[-1] - Z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralDenseLayer(DeepShapeLayer):\n",
    "    def __init__(self, input_dim: int, output_dim: int, activation: str = \"tanh\", bias=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Init Weights\n",
    "        self.linear = nn.Linear(input_dim, output_dim, bias=True)\n",
    "#         self.project(c=0.9, iters=5)\n",
    "        \n",
    "        if activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(activation)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear(x))\n",
    "        \n",
    "    def project(self, c : float, iters: int = 5):\n",
    "        with torch.no_grad():\n",
    "            self.linear.weight = nuclear_normalization(self.linear.weight, c, iters)\n",
    "\n",
    "class SpectralResidualLayer(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_layers: int, hidden_dim: int,\n",
    "                 activation: str = \"tanh\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create layer list\n",
    "        self.layers = nn.ModuleList([SpectralDenseLayer(input_dim, hidden_dim, activation)])\n",
    "        for _ in range(hidden_layers-1):\n",
    "            self.layers.append(SpectralDenseLayer(hidden_dim, hidden_dim, activation))\n",
    "        self.layers.append(SpectralDenseLayer(hidden_dim, input_dim, activation))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for layer in self.layers:\n",
    "            y = layer(y)\n",
    "        return min_max_norm(x + y)\n",
    "    \n",
    "    def project(self, c: float, iters: int = 5):\n",
    "        with torch.no_grad():\n",
    "            for layer in self.layers:\n",
    "                layer.project(c, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SpectralResidualLayer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_87511/2868074432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"SpectralResLayer{l}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpectralResidualLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SpectralResidualLayer' is not defined"
     ]
    }
   ],
   "source": [
    "########################################################### \n",
    "# Test 1: Check that spectral_resnet indeed preserves order\n",
    "###########################################################\n",
    "add_iters = 1\n",
    "input_size = 1\n",
    "hidden_size = 128\n",
    "c = 0.9\n",
    "inner_layers = 1\n",
    "outer_layers = 20\n",
    "num_layers = 1\n",
    "\n",
    "\n",
    "# # Create network with [num_layers layers]\n",
    "network = nn.Sequential()\n",
    "for l in range(outer_layers):\n",
    "    network.add_module(f\"SpectralResLayer{l}\", SpectralResidualLayer(input_size, inner_layers, hidden_size, \"relu\"))\n",
    "network\n",
    "\n",
    "# Data to be used.\n",
    "x = torch.linspace(0, 1, 21).unsqueeze(-1)\n",
    "Z = x.clone().transpose(0, 1)\n",
    "y = x.clone()\n",
    "\n",
    "# Multiple attempts\n",
    "for i in range(add_iters):\n",
    "    # Want to modify parameters without keeping track of operations.\n",
    "    with torch.no_grad():\n",
    "        for layer in next(network.modules()):\n",
    "            y = layer(y)\n",
    "            Z = torch.vstack((Z, y.clone().transpose(0, 1)))\n",
    "\n",
    "        # Plot network.\n",
    "        plt.figure()\n",
    "        plt.plot(Z)\n",
    "        plt.show()\n",
    "\n",
    "        assert (np.diff(y.flatten()) > 0.0).all(), \"Layer not invertible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `reparametrize` not found.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ShapeDistance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_87511/183943453.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pinfo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reparametrize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreparametrize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ShapeDistance' is not defined"
     ]
    }
   ],
   "source": [
    "?reparametrize\n",
    "loss = ShapeDistance(q, r, 256)\n",
    "opt = torch.optim.SGD(network.parameters(), lr=1e-3)\n",
    "reparametrize(q, r, network, loss, opt, 10, logger=Logger(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, r, network, optimizer, scheduler=None, loss=nn.MSELoss(), \n",
    "          npoints=1024, iterations=300, epsilon=None, log_every=10):\n",
    "    \"\"\" General purpose function for training a curve reparametrization network,\n",
    "    which works with most optimizers not requiring a closure.\n",
    "\n",
    "    TODO: Implement as method of the network.\n",
    "    \"\"\"\n",
    "    tic = time.time()\n",
    "    \n",
    "    # Initialize node placement\n",
    "    x = torch.linspace(0, 1, npoints).unsqueeze(-1)\n",
    "    \n",
    "    # Evaluate initial error\n",
    "    error = np.empty(iterations+1)\n",
    "    error.fill(np.nan)\n",
    "    # Find current reparametrized Q-maps\n",
    "    Z = network(x)\n",
    "    Y = central_diff_derivative(Z)\n",
    "    Q = q(x)\n",
    "    R = torch.sqrt(Y) * r(Z)\n",
    "    error[0] = loss(R, Q) * 2\n",
    "\n",
    "\n",
    "    for i in range(iterations):   \n",
    "        x = torch.linspace(0, 1, npoints).unsqueeze(-1)\n",
    "        \n",
    "        # Set gradient buffers to zero.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Find current reparametrized Q-maps\n",
    "        Z = network(x)\n",
    "        Y = central_diff_derivative(Z)\n",
    "        Q = q(x)\n",
    "        R = torch.sqrt(Y) * r(Z)\n",
    "\n",
    "        # Compute loss, and perform a backward pass and gradient step\n",
    "        l = loss(R, Q) * 2\n",
    "        l.backward()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(l)\n",
    "        \n",
    "        optimizer.step()\n",
    "        error[i+1] = l.item()\n",
    "\n",
    "        # Projection step\n",
    "        with torch.no_grad():\n",
    "            for layer in next(network.modules()):\n",
    "                layer.project(2.)\n",
    "\n",
    "        if log_every > 0 and i % log_every == 0:\n",
    "            print('[Iter %5d] loss: %.5f' %\n",
    "                  (i + 1, l))        \n",
    "\n",
    "    toc = time.time()\n",
    "\n",
    "    print()\n",
    "    print(f'Finished training in {toc - tic:.5f}s')\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_resnet(hidden_size, num_layers):\n",
    "    # Create network with [num_layers layers]\n",
    "    network = nn.Sequential()\n",
    "    for l in range(num_layers):\n",
    "        network.add_module(f\"SpectralDense{l}\", SpectralDense(input_size, hidden_size))\n",
    "    return network\n",
    "\n",
    "def central_diff_derivative(x):\n",
    "    out = torch.zeros_like(x)\n",
    "    out[0] = x[1] - x[0]\n",
    "    out[-1] = x[-1] - x[-2]\n",
    "    out[1:-1] = 0.5 * (x[2:] - x[:-2])\n",
    "    return out / x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SpectralDense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_87511/1064106774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectral_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Choose and configure optimizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_87511/4010134278.py\u001b[0m in \u001b[0;36mspectral_resnet\u001b[0;34m(hidden_size, num_layers)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"SpectralDense{l}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpectralDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SpectralDense' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "RN = spectral_resnet(256, 10)\n",
    "\n",
    "\n",
    "# Choose and configure optimizer.\n",
    "optimizer = optim.SGD(RN.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler=None\n",
    "error = train(q, r, RN, optimizer, scheduler=scheduler, iterations=10, log_every=1)\n",
    "\n",
    "# Create Plotting Data to verify reparametrizations\n",
    "Npoints = 128\n",
    "h = 1 / (Npoints )\n",
    "x = torch.linspace(0, 1, Npoints).unsqueeze(-1)\n",
    "z = min_max_norm(RN(x))\n",
    "y = central_diff_derivative(z)\n",
    "z, y = z.detach(), y.detach()\n",
    "Q, R = q(x), torch.sqrt(y) * r(z)\n",
    "R = R.detach()\n",
    "\n",
    "# Plot Diffeomorphism...\n",
    "plt.figure(figsize=(8.4, 5.6))\n",
    "plt.plot(x, z, label=\"Found\", lw=1.5)\n",
    "plt.plot(x, g(x), label=\"Analytic\", ls=\"--\", c=\"black\", lw=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
